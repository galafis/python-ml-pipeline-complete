# Python ML Pipeline Completo

![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=fastapi&logoColor=white)
![Pytest](https://img.shields.io/badge/pytest-0A9EDC?style=flat&logo=pytest&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

![Hero Image](docs/hero_image.png)

## üéØ Vis√£o Geral

Este reposit√≥rio apresenta um **pipeline de Machine Learning (ML) completo e robusto** desenvolvido em Python. Ele abrange todas as etapas essenciais de um projeto de ML, desde a ingest√£o e pr√©-processamento de dados at√© o treinamento, avalia√ß√£o, serializa√ß√£o de modelos e, finalmente, a disponibiliza√ß√£o via API RESTful. O objetivo √© fornecer uma estrutura modular e escal√°vel para o desenvolvimento e implanta√ß√£o de solu√ß√µes de ML.

### ‚ú® Caracter√≠sticas Principais:

*   **Modularidade**: Componentes bem definidos para cada etapa do pipeline (carregamento de dados, engenharia de features, treinamento, avalia√ß√£o).
*   **Flexibilidade**: Suporte a diferentes modelos de ML (Regress√£o Log√≠stica, Random Forest, SVM) e f√°cil extens√£o para outros algoritmos.
*   **API RESTful**: Integra√ß√£o com FastAPI para servir previs√µes em tempo real.
*   **Testes Abrangentes**: Testes unit√°rios e de integra√ß√£o para garantir a robustez e corre√ß√£o do c√≥digo.
*   **Configura√ß√£o Externa**: Gerenciamento de configura√ß√µes via arquivos YAML.
*   **Containeriza√ß√£o**: Suporte a Docker para empacotamento e implanta√ß√£o facilitada.

## üéØ Overview

This repository presents a **complete and robust Machine Learning (ML) pipeline** developed in Python. It covers all essential stages of an ML project, from data ingestion and preprocessing to model training, evaluation, serialization, and finally, deployment via a RESTful API. The goal is to provide a modular and scalable framework for developing and deploying ML solutions.

### ‚ú® Key Features:

*   **Modularity**: Well-defined components for each pipeline stage (data loading, feature engineering, training, evaluation).
*   **Flexibility**: Support for various ML models (Logistic Regression, Random Forest, SVM) and easy extension to other algorithms.
*   **RESTful API**: Integration with FastAPI for serving real-time predictions.
*   **Comprehensive Testing**: Unit and integration tests to ensure code robustness and correctness.
*   **External Configuration**: Configuration management via YAML files.
*   **Containerization**: Docker support for easy packaging and deployment.

## Sum√°rio

1.  [Vis√£o Geral](#vis√£o-geral)
2.  [Estrutura do Projeto](#estrutura-do-projeto)
3.  [Instala√ß√£o](#instala√ß√£o)
4.  [Uso](#uso)
5.  [API](#api)
6.  [Testes](#testes)
7.  [Arquitetura](#arquitetura)
8.  [Contribui√ß√£o](#contribui√ß√£o)
9.  [Licen√ßa](#licen√ßa)

## Table of Contents

1.  [Overview](#overview)
2.  [Project Structure](#project-structure)
3.  [Installation](#installation)
4.  [Usage](#usage)
5.  [API](#api-1)
6.  [Testing](#testing)
7.  [Architecture](#architecture)
8.  [Contribution](#contribution)
9.  [License](#license-1)

## üìÅ Estrutura do Projeto

```
python-ml-pipeline-complete/
‚îú‚îÄ‚îÄ config/                 # Arquivos de configura√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml
‚îú‚îÄ‚îÄ data/                   # Dados do projeto
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Dados brutos
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Dados processados
‚îÇ   ‚îî‚îÄ‚îÄ features/           # Features engenheiradas
‚îú‚îÄ‚îÄ docs/                   # Documenta√ß√£o e diagramas
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_architecture.mmd
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_architecture.png
‚îú‚îÄ‚îÄ docker/                 # Arquivos Docker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ k8s/                    # Configura√ß√µes Kubernetes
‚îÇ   ‚îî‚îÄ‚îÄ deployment.yaml
‚îú‚îÄ‚îÄ models/                 # Modelos treinados e serializados
‚îú‚îÄ‚îÄ notebooks/              # Notebooks de explora√ß√£o e experimenta√ß√£o
‚îú‚îÄ‚îÄ reports/                # Relat√≥rios de avalia√ß√£o e an√°lises
‚îú‚îÄ‚îÄ src/                    # C√≥digo fonte da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ api/                # Implementa√ß√£o da API FastAPI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app_dashboard.py    # Exemplo de dashboard (se aplic√°vel)
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py      # M√≥dulo de carregamento de dados
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py # M√≥dulo de engenharia de features
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Ponto de entrada do pipeline CLI
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluator.py  # M√≥dulo de avalia√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py    # M√≥dulo de treinamento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.py       # M√≥dulo de monitoramento (se aplic√°vel)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py         # Orquestrador do pipeline ML
‚îú‚îÄ‚îÄ tests/                  # Testes unit√°rios e de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îú‚îÄ‚îÄ .gitignore              # Arquivos e pastas a serem ignorados pelo Git
‚îú‚îÄ‚îÄ LICENSE                 # Arquivo de licen√ßa
‚îú‚îÄ‚îÄ README.md               # Este arquivo
‚îî‚îÄ‚îÄ requirements.txt        # Depend√™ncias do projeto
```

## üìÅ Project Structure

```
python-ml-pipeline-complete/
‚îú‚îÄ‚îÄ config/                 # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml
‚îú‚îÄ‚îÄ data/                   # Project data
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Raw data
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Processed data
‚îÇ   ‚îî‚îÄ‚îÄ features/           # Engineered features
‚îú‚îÄ‚îÄ docs/                   # Documentation and diagrams
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_architecture.mmd
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_architecture.png
‚îú‚îÄ‚îÄ docker/                 # Docker files
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ k8s/                    # Kubernetes configurations
‚îÇ   ‚îî‚îÄ‚îÄ deployment.yaml
‚îú‚îÄ‚îÄ models/                 # Trained and serialized models
‚îú‚îÄ‚îÄ notebooks/              # Exploration and experimentation notebooks
‚îú‚îÄ‚îÄ reports/                # Evaluation reports and analyses
‚îú‚îÄ‚îÄ src/                    # Application source code
‚îÇ   ‚îú‚îÄ‚îÄ api/                # FastAPI API implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app_dashboard.py    # Example dashboard (if applicable)
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py      # Data loading module
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py # Feature engineering module
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # CLI pipeline entry point
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluator.py  # Model evaluation module
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py    # Model training module
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.py       # Monitoring module (if applicable)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py         # ML pipeline orchestrator
‚îú‚îÄ‚îÄ tests/                  # Unit and integration tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îú‚îÄ‚îÄ .gitignore              # Files and folders to be ignored by Git
‚îú‚îÄ‚îÄ LICENSE                 # License file
‚îú‚îÄ‚îÄ README.md               # This file
‚îî‚îÄ‚îÄ requirements.txt        # Project dependencies
```

## Instala√ß√£o

Para configurar o ambiente de desenvolvimento e executar o pipeline, siga os passos abaixo:

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/GabrielDemetriosLafis/python-ml-pipeline-complete.git
    cd python-ml-pipeline-complete
    ```

2.  **Crie e ative um ambiente virtual (recomendado):**

    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: .venv\Scripts\activate
    ```

3.  **Instale as depend√™ncias:**

    ```bash
    pip install -r requirements.txt
    ```

## Installation

To set up the development environment and run the pipeline, follow these steps:

1.  **Clone the repository:**

    ```bash
    git clone https://github.com/GabrielDemetriosLafis/python-ml-pipeline-complete.git
    cd python-ml-pipeline-complete
    ```

2.  **Create and activate a virtual environment (recommended):**

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: .venv\Scripts\activate
    ```

3.  **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

## Uso

O pipeline pode ser executado via linha de comando. Certifique-se de ter ativado seu ambiente virtual.

### Treinamento e Avalia√ß√£o de Modelo:

Para treinar e avaliar um modelo, use o script `main.py`:

```bash
python -m src.main --data data/raw/dummy_data.csv --model logistic --output models/model.joblib --verbose
```

**Argumentos:**

*   `--data` ou `-d`: Caminho para o arquivo CSV de dados de entrada.
*   `--model` ou `-m`: Tipo de modelo a ser usado (`logistic`, `random_forest`, `svm`).
*   `--output` ou `-o`: Caminho para salvar o modelo treinado (padr√£o: `model.joblib`).
*   `--test-size`: Propor√ß√£o dos dados para teste (padr√£o: `0.2`).
*   `--random-state`: Seed para reprodutibilidade (padr√£o: `42`).
*   `--verbose` ou `-v`: Ativa o modo verboso para informa√ß√µes detalhadas.

**Par√¢metros Espec√≠ficos do Modelo:**

*   `--max-iter` (LogisticRegression): N√∫mero m√°ximo de itera√ß√µes.
*   `--C` (LogisticRegression/SVM): Par√¢metro de regulariza√ß√£o.
*   `--n-estimators` (RandomForestClassifier): N√∫mero de √°rvores.
*   `--max-depth` (RandomForestClassifier): Profundidade m√°xima das √°rvores.
*   `--kernel` (SVM): Kernel do SVM (`linear`, `poly`, `rbf`, `sigmoid`).

## Usage

The pipeline can be executed via the command line. Make sure you have activated your virtual environment.

### Model Training and Evaluation:

To train and evaluate a model, use the `main.py` script:

```bash
python -m src.main --data data/raw/dummy_data.csv --model logistic --output models/model.joblib --verbose
```

**Arguments:**

*   `--data` or `-d`: Path to the input CSV data file.
*   `--model` or `-m`: Type of model to use (`logistic`, `random_forest`, `svm`).
*   `--output` or `-o`: Path to save the trained model (default: `model.joblib`).
*   `--test-size`: Proportion of data for testing (default: `0.2`).
*   `--random-state`: Seed for reproducibility (default: `42`).
*   `--verbose` or `-v`: Activates verbose mode for detailed information.

**Model-Specific Parameters:**

*   `--max-iter` (LogisticRegression): Maximum number of iterations.
*   `--C` (LogisticRegression/SVM): Regularization parameter.
*   `--n-estimators` (RandomForestClassifier): Number of trees.
*   `--max-depth` (RandomForestClassifier): Maximum tree depth.
*   `--kernel` (SVM): SVM kernel (`linear`, `poly`, `rbf`, `sigmoid`).

## API

A API RESTful √© constru√≠da com FastAPI e permite servir previs√µes do modelo treinado. Para iniciar a API:

```bash
cd python-ml-pipeline-complete
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

Ap√≥s iniciar, a documenta√ß√£o interativa da API estar√° dispon√≠vel em `http://localhost:8000/docs`.

### Endpoints:

*   **GET /**: Health check da API.
*   **GET /model/info**: Retorna informa√ß√µes sobre o modelo carregado.
*   **POST /predict**: Recebe dados e retorna previs√µes.
    *   **Request Body**: `{"data": [[feature1, feature2, ...]]}`
    *   **Response**: `{"prediction": [pred1, pred2, ...], "status": "success"}`
*   **POST /predict/batch**: Endpoint para predi√ß√µes em lote.
*   **POST /reload-model**: Recarrega o modelo do disco.

## API

 The RESTful API is built with FastAPI and allows serving predictions from the trained model. To start the API:

```bash
cd python-ml-pipeline-complete
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

Once started, the interactive API documentation will be available at `http://localhost:8000/docs`.

### Endpoints:

*   **GET /**: API health check.
*   **GET /model/info**: Returns information about the loaded model.
*   **POST /predict**: Receives data and returns predictions.
    *   **Request Body**: `{"data": [[feature1, feature2, ...]]}`
    *   **Response**: `{"prediction": [pred1, pred2, ...], "status": "success"}`
*   **POST /predict/batch**: Endpoint for batch predictions.
*   **POST /reload-model**: Reloads the model from disk.

## Testes

Os testes unit√°rios e de integra√ß√£o garantem a qualidade e a funcionalidade do pipeline. Para execut√°-los:

```bash
cd python-ml-pipeline-complete
pytest
```

## Testing

Unit and integration tests ensure the quality and functionality of the pipeline. To run them:

```bash
cd python-ml-pipeline-complete
pytest
```

## Arquitetura

O diagrama abaixo ilustra a arquitetura do pipeline de Machine Learning, destacando o fluxo de dados e as intera√ß√µes entre os componentes.

```mermaid
%%{init: {"themeVariables": {"fontFamily": "sans-serif"}}}%%
graph TD
    A[In√≠cio] --> B(Coleta de Dados)
    B --> C{Pr√©-processamento de Dados}
    C --> D[Engenharia de Features]
    D --> E(Divis√£o Treino/Teste)
    E --> F[Treinamento do Modelo]
    F --> G{Avalia√ß√£o do Modelo}
    G --> H{Otimiza√ß√£o do Modelo}
    H -- Feedback --> F
    G --> I[Serializa√ß√£o do Modelo]
    I --> J(Implanta√ß√£o da API)
    J --> K[Previs√µes em Tempo Real]
    K --> L[Monitoramento]
    L -- Feedback --> C
    L -- Feedback --> H
```

![Diagrama de Arquitetura do Pipeline ML](docs/pipeline_architecture.png)

## Architecture

The diagram below illustrates the architecture of the Machine Learning pipeline, highlighting the data flow and interactions between components.

```mermaid
%%{init: {"themeVariables": {"fontFamily": "sans-serif"}}}%%
graph TD
    A[Start] --> B(Data Collection)
    B --> C{Data Preprocessing}
    C --> D[Feature Engineering]
    D --> E(Train/Test Split)
    E --> F[Model Training]
    F --> G{Model Evaluation}
    G --> H{Model Optimization}
    H -- Feedback --> F
    G --> I[Model Serialization]
    I --> J(API Deployment)
    J --> K[Real-time Predictions]
    K --> L[Monitoring]
    L -- Feedback --> C
    L -- Feedback --> H
```

![ML Pipeline Architecture Diagram](docs/pipeline_architecture.png)

## Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Siga estas diretrizes:

1.  Fa√ßa um fork do reposit√≥rio.
2.  Crie uma nova branch (`git checkout -b feature/sua-feature`).
3.  Implemente suas mudan√ßas e escreva testes adequados.
4.  Certifique-se de que todos os testes passem.
5.  Fa√ßa commit de suas mudan√ßas (`git commit -m 'Adiciona nova feature'`).
6.  Envie para a branch (`git push origin feature/sua-feature`).
7.  Abra um Pull Request.

## Contribution

Contributions are welcome! Please follow these guidelines:

1.  Fork the repository.
2.  Create a new branch (`git checkout -b feature/your-feature`).
3.  Implement your changes and write appropriate tests.
4.  Ensure all tests pass.
5.  Commit your changes (`git commit -m 'Add new feature'`).
6.  Push to the branch (`git push origin feature/your-feature`).
7.  Open a Pull Request.

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

---

**Autor:** Gabriel Demetrios Lafis

---

**Author:** Gabriel Demetrios Lafis

